---
title: "Asssignment 1"
author: "Nigel"
date: '2022-09-04'
output:
  word_document: default
  pdf_document: default
  html_document:
    df_print: paged
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
library(tidyverse)
library(lubridate)
library(GGally)
library(zoo)
```

## Data

```{r import data, include=FALSE}
weather_data <- read.csv("weather_data.csv", sep = ",")
sales_data <- read.csv("sales_data.csv", sep = ",")
```

### 1. Describe your data visually and numerically
Both data sets contained mixed variables.

The weather data set consists of 422 observations and 23 variables. This data set records daily weather conditions including temperature, wind, humidity, rainfall, etc.

```{r dimensions_weather, echo=TRUE}
dim(weather_data)
```

The sales data set consists of 326 observations and 10 variables. This data set records daily sales and details the source of sales including UberEats, Menulog, Deliveroo sales, and cash and eftpos sales. Unlike the weather data, our sales data only recorded the past 12 months as opposed to the past 14 months.

```{r dimensions_sales, echo=TRUE}
dim(sales_data)
```

### 2. Provide details of the pre-processing undertaken in order to meet the conditions of your chosen modelling techniques.
The variable names given to the weather data were renamed to aid in pre-processing. 

```{r rename_weather, echo=FALSE}
colnames(weather_data) <- c("date", "min_temp", "max_temp", "rainfall", "evap", 
                            "sun_sh_hr", "dir_max_wind", "spd_max_wind", "tm_max_wind", 
                            "9am_temp", "9am_hum", "9am_cld_amnt", "9am_wind_dir", "9am_wind_spd", "9am_pres",
                            "3pm_temp", "3pm_hum", "3pm_cld_amnt", "3pm_wind_dir", "3pm_wind_spd", "3pm_pres",
                            "rain_today", "rain_tmrw")
```

Next, we formatted the "date" column to the date data type. This allows us to create a "month" and "year" variable so that we can create time-series graphs further into the investigation.

```{r feature_creation_date_weather, echo=FALSE}
# Format "Date" columns
weather_data$date <- as.Date(weather_data$date, format = "%d/%m/%Y")
weather_data <- weather_data[order(as.Date(weather_data$date, format = "%d/%m/%Y")), ]

# Create "month", "year", and "year_month" variable
weather_data$month <- months(as.POSIXlt(weather_data$date, format = "%Y-%m-%d"))
weather_data$year <- year(as.POSIXlt(weather_data$date, format = "%Y-%m-%d"))
weather_data$yr_month <- as.yearmon(weather_data$date)
```

The weather data set contained very few NA values. 

```{r NAs_weather, echo=FALSE}
colSums(is.na(weather_data))
```

To be able to measure the correlation between the tow data sets, they both must contain the same amount of observations. To do this, we subset the weather data by the range of the dates of the sales data. 

```{r remove_rows, echo=FALSE}
weather_data <- subset(weather_data, date > as.Date("2021-09-26"))
weather_data <- subset(weather_data, date < as.Date("2022-08-19"))
```

Using these variables we are able to impute the NA values by "yr_month".

```{r impute_weather, echo=FALSE}
weather_data <- as.data.frame(weather_data %>% group_by(year, month) %>%
                                mutate(max_temp = ifelse(is.na(max_temp),
                                                         mean(max_temp, na.rm = TRUE), max_temp)))

weather_data <- as.data.frame(weather_data %>% group_by(year, month) %>%
                                mutate(rainfall = ifelse(is.na(rainfall),
                                                         mean(rainfall, na.rm = TRUE), rainfall)))

weather_data <- as.data.frame(weather_data %>% group_by(year, month) %>%
                                mutate(sun_sh_hr = ifelse(is.na(sun_sh_hr),
                                                         mean(rainfall, na.rm = TRUE), sun_sh_hr)))

weather_data <- as.data.frame(weather_data %>% group_by(year, month) %>%
                                mutate(spd_max_wind = ifelse(is.na(spd_max_wind),
                                                         mean(spd_max_wind, na.rm = TRUE), spd_max_wind)))

weather_data <- as.data.frame(weather_data %>% group_by(year, month) %>%
                                mutate(`9am_hum` = ifelse(is.na(`9am_hum`),
                                                         mean(`9am_hum`, na.rm = TRUE), `9am_hum`)))

weather_data <- as.data.frame(weather_data %>% group_by(year, month) %>%
                                mutate(`9am_cld_amnt` = ifelse(is.na(`9am_cld_amnt`),
                                                          mean(`9am_cld_amnt`, na.rm = TRUE), `9am_cld_amnt`)))
```

Two separate .csv files were used to create the sales data set. One recorded sales data for 2021 and the other for 2022. The 2022 file contained an extra variable recording eftpos sales including the surcharge. This variable was the “Card” variable multiplied by the surcharge (1.011%). This variable was removed as it was deemed unnecessary. 

```{r removed_column, echo=FALSE}
sales_data <- subset(sales_data, select = -c(X))
```

Next, the variable names were renamed to keep consistency during pre-processing.

```{r rename_sales, echo=FALSE}
colnames(sales_data) <- c("date", "day", "ubereats", "menulog", "deliveroo", "card", "cash", "total", "petty_cash")
```

We also created a “month” and “year” variable for this data set using the same method as the weather data set.

```{r feature_creation, echo=FALSE}
sales_data$month <- months(as.POSIXlt(sales_data$date, format = "%Y-%m-%d"))
sales_data$year <- year(as.POSIXlt(sales_data$date, format = "%Y-%m-%d"))
sales_data$yr_month <- as.yearmon(sales_data$date)
```

The sales data contained numerous NA values. 

```{r NAs_sales, echo=FALSE}
colSums(is.na(sales_data))
```

```{r replace_NA, echo=FALSE}
sales_data[is.na(sales_data)] <- 0
```

Next we combine the two datasets so that we can create a correlation matrix to determine the significant variables for our chosen models. The “uber”, “menulog”, “deliveroo”, and “total” variables were appended to the weather data to create a master data frame. Next, the “rain_today” and “rain_tmrw” variables were modified to contain binary values. Then we removed the observations where total sales equals zero. Next, we created a "wk_num" variable and a numeric "month" variable. These allow us to create more fine-tuned visualisations.

Finally, we created a subset of the master data frame containing only numeric variables to allow for the creation of the correlation matrix.

```{r master_df, echo=FALSE}
master_df <- cbind(weather_data, sales_data)
master_df <- subset(master_df, select = -c(24, 25, 26, 27, 28, 35))
master_df$rain_today <- ifelse(master_df$rain_today == "Yes", 1, 0)
master_df$rain_tmrw <- ifelse(master_df$rain_tmrw == "Yes", 1, 0)
master_df <- master_df[!master_df$total == 0, ]
master_df$month <- as.integer(factor(master_df$month, levels = month.name))
master_df$wk_num <- strftime(master_df$date, format = "%V")
```

```{r average_monthly, echo=FALSE}
avg_mnth_master_df <- master_df %>%
  group_by(yr_month) %>%
  summarise(
    min_temp = mean(min_temp, na.rm = FALSE),
    max_temp = mean(max_temp, na.rm = FALSE),
    rainfall = mean(rainfall, na.rm = FALSE),
    ubereats = mean(ubereats, na.rm = FALSE),
    menulog = mean(menulog, na.rm = FALSE),
    deliveroo = mean(deliveroo, na.rm = FALSE),
    card = mean(card, na.rm = FALSE),
    cash = mean(cash, na.rm = FALSE),
    total = mean(total, na.rm = FALSE)
  )
```

```{r correlation_matrix, echo=FALSE}
corr_avg_mnth_master_df <- subset(avg_mnth_master_df, select = -c(1))
ggcorr(corr_avg_mnth_master_df, label = TRUE)
```
